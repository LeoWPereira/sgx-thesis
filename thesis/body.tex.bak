


% color definitions
\colorlet{greenbg}{green!50!white}
\colorlet{redbg}{red!50!white}
\colorlet{orangebg}{orange!50!white}
% styles
%\tikzstyle{block} = [rectangle, draw, align=center, rounded corners]
%\tikzstyle{line} = [draw, -latex']
%\tikzstyle{legend} = [nodes={anchor=base}, column sep=5pt, row %sep=5pt, yshift=-2cm, anchor=north]
%\tikzstyle{legend heading} = [gray]
%\tikzstyle{heading} = [minimum height=0.2cm]
%\tikzstyle{edge label} = [midway, above, minimum width=0]
%\tikzstyle{myperson} = [minimum size=40pt, person]
%\tikzstyle{computer} = [draw, dotted]

% lengths
\newlength{\haloOffset}
\newlength{\personOffset}
\setlength{\haloOffset}{13pt}
\setlength{\personOffset}{3pt}
\lstdefinestyle{default}{
  breaklines=true,
  postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}\space},
}

\lstdefinestyle{cpp}{
  language=C++,
  style=default
}
\lstdefinestyle{edl}{ style=cpp, morekeywords={enclave, trusted, untrusted, from, import, include, in, out, size, readonly, string, uint8_t} }\label{ID_605614845}

\chapter{Introduction\label{ID_1883383221}}
protect from privilege escalation\label{ID_173367700}
select a trusted computing solution (ready to use, small TCB, attestation)\label{ID_1396932272}
assumption: can modify application\label{ID_1426216513}

\begin{figure}[htbp]
\begin{center}
	\includegraphics[width=0.7\textwidth]{content/images/trusted computing cartoon}
\caption{\textbf{Trusted computing cartoon.} Left computer: ``Do you also sometimes feel remotely controlled by this trusted computing module?''. Right computer: ``I don't know, let me ask my manufacturer.'' Reprinted from \cite[]{ix-enclave}\label{ID_863606381}\label{figure:tc-cartoon}\label{ID_863606381}\label{figure:tc-cartoon}}

\end{center}
\end{figure}


\chapter{Background\label{ID_941070001}}
Nowadays, data is oftentimes not stored -- and applications are not executed -- locally (on premise) any more. Rather, these tasks are outsourced to hosted, remote infrastructure. In addition, computer technology is becoming increasingly pervasive in our lives. More data is stored on and processed by computers, making them ever more valuable targets.\label{ID_1470188624}
\begin{figure}[htbp]
\begin{center}\input{content/tikz/data-lifecycle}
\caption{\textbf{Focus of this thesis within the data life cycle.}\label{ID_1160378356}
Transmitting and storing data can be secured using encryption (green). The applications examined in this thesis deal with processing data (red). This is an area of active research.\label{ID_745166579}
\label{ID_671023153}\label{figure:data-lifecycle}}

\end{center}
\end{figure}

The state of the art is to protect sensitive data by \textit{encrypting} it while it is at rest or being transmitted. This is shown in \autoref{figure:data-lifecycle}.\label{ID_1880219695}
Protecting the processing stage is an active field of research called \textit{secure remote computation}.\label{ID_1852842699}
\begin{figure}[htbp]
\begin{center}\input{content/tikz/secure-remote-computation}
\caption{\textbf{Secure remote computation.}\label{ID_1573575704}
The data owner trusts the software provider but not the infrastructure owner. The code and data within the trusted execution environment (green) must be protected. There are different options for implementing this protection.\label{ID_532436106}
Reprinted from\label{ID_28551827}
 \cite[]{sgx-explained}\label{ID_50207747}\label{figure:secure-remote-computation}}

\end{center}
\end{figure}

\autoref{figure:secure-remote-computation} gives an abstract overview of the entities and steps involved in secure remote computation. For the sake of this thesis, the most interesting part of the picture is the implementation of the container.\label{ID_1217277821}

Arasu et al.\@ categorise the approaches for constructing such a container that can protect code and data on a remote computer: \cite[p. 19]{querying-encrypted-data-tutorial}\label{ID_500367217}
\begin{description}\label{ID_27140838}
\item[Compute on encrypted data] The data remains encrypted during processing. Thus the results are also encrypted. In this case the cryptographic scheme is the container. No information about the plain text should be leaked. \autoref{crypto} explains which encryption schemes support this.\label{ID_328666411}
\item[Decrypt and process data in a secure location] Such a location could be a local machine, disconnected from the internet, or a remote trusted hardware component such as a secure co-processor. Whether or not a location is deemed secure is a subjective decision. This variant of implementing the container is called \textit{trusted computing}.\label{ID_481899872}
\end{description}\label{ID_933485978}
The remainder of this chapter explains the fundamental concepts of both these approaches.\label{ID_1721841145}

Implementations of the first approach are presented later on in \autoref{section:secure-db}.\label{ID_1199323088}
Implementations of trusted computing are described and compared in \autoref{chapter:tc-solutions}.\label{ID_684830290}
Intel SGX -- a particular commercial solution for trusted computing -- is described in more detail in \autoref{chapter:sgx}.\label{ID_733461445}

\section{Cryptography\label{ID_265480959}\label{crypto}}
There are several different ways in which cryptographic principles can be used to implement the concept of a secure container.\label{ID_544485861}
\begin{description}\label{ID_958111314}
\item[Multi party computing]\label{ID_1564094585}
Several parties jointly compute a function to which every party provides some input. The input of each party is not revealed to any of the other parties. One early implementation is Yao's garbled circuits. \cite[]{Gupta}\label{ID_1507598191}
For secure remote computation, we could assume two parties, where only the data owner provides an input and only the infrastructure owner executes the function.\label{ID_1818312817}
However, the function output is in plain text which is not desirable for secure remote computation in general.\label{ID_647862117}
\item[Verifiable computing]\label{ID_1000386877}
This is a first step in the direction of secure remote computing. It ensures the integrity but not the confidentiality of the computation (similar to a cryptographic signature). \cite[]{Gennaro2010}\label{ID_14679414}
 \cite[]{Karapanos}
 \cite[]{Vu2013}
\item[Homomorphic Encryption]\label{ID_1769833687}
Such encryption schemes define calculation operations on encrypted data. The operands and result of these calculations remain encrypted so they could be performed by an untrusted third party.\label{ID_1952238538}
Homomorphic encryption schemes and their usefulness for secure remote computing are explained in more detail in \autoref{section:homomorphic-encryption}.\label{ID_586952145}
\item[Encrypted CPU]\label{ID_1403278513}
Given a (fully) homomorphic encryption scheme it is possible to execute entire encrypted programs. This is possible in a fully oblivious fashion where both the instruction flow and memory access (code and data) remain hidden.\label{ID_601974181}
Both obliviousness and the current fully homomorphic encryption schemes incur such large performance penalties that they are not yet practically useful for more complex programs.\label{ID_312856627}
More details are given in \autoref{section:encrypted-cpu}.\label{ID_249466965}
\end{description}\label{ID_408605672}
\subsection{Homomorphic Encryption\label{ID_499374671}\label{section:homomorphic-encryption}}
\autoref{figure:homomorphic-encryption} explains the principle of homomorphic encryption with an example. While partially homomorphic schemes define only one operation (e.g. either addition or multiplication), fully homomorphic schemes define both.\label{ID_1116118751}
\begin{figure}[htbp]
\begin{center}\input{content/tikz/homomorphic-encryption}
\caption{\textbf{Homomorphic encryption example.}\label{ID_610399076}
A homomorphic encryption scheme defines operations on encrypted data. The decrypted result of the encrypted addition ($\bigoplus$) gives the same result as performing a plain text addition ($+$). Using this scheme an untrusted \textit{processing provider} can perform calculations without learning anything about the plain text.\label{ID_1072580727}
\label{ID_1989105116}\label{figure:homomorphic-encryption}}

\end{center}
\end{figure}

Gentry et al. successfully constructed the first fully homomorphic scheme in 2009. \cite[]{Gentry2009}\label{ID_233387469}
\autoref{figure:encryption-schemes} shows the relationship between different encryption schemes and the operations they support. These schemes are revisited in \autoref{section:secure-db}, which also shows how they can be practically put to use.\label{ID_129969722}
\begin{figure}[htbp]
\begin{center}\input{content/tikz/encryption-schemes}
\caption{\textbf{Encryption schemes and their relationships.}\label{ID_489936542}
The shading indicates computational efficiency (red: impractical, orange: expensive, green: practical). Arrows indicate subsumption of functionality. Fully homomorphic schemes for example provide both $+$ and $\times$ operations (and by extension -- e.g. an encrypted CPU -- also comparison operations).\label{ID_1527882742}
Reprinted from\label{ID_467588759}
 \cite[]{querying-encrypted-data-tutorial}\label{ID_452615921}\label{figure:encryption-schemes}}

\end{center}
\end{figure}

State of the art fully homomorphic schemes still suffer from an intractably high overhead. Partially homomorphic schemes on the other hand have already been applied to databases.\label{ID_1599544022}
 \cite[]{Baumann2014}
 \cite[]{querying-encrypted-data-tutorial}

Encryption schemes in themselves also do not help verify what computation took place. Combining encryption with verifiable computation approaches or software attestation may provide a solution.\label{ID_717622838}
\subsection{Encrypted CPU\label{ID_1925936219}\label{section:encrypted-cpu}}
The encrypted CPU works very much the same as a regular CPU, as can be seen in \autoref{figure:encrypted-cpu}. A regular CPU operates on bits using logical gates. The encrypted CPU operates on encrypted bits. Each bit is represented by cipher value of $n$ bits size so that there are $2^{n-1}$ possible representations for $0$ and $1$ respectively. Logical gates are emulated using the fully homomorphic operations on these cipher values (addition and multiplication). \cite[]{Brenner2011}\label{ID_1020198095}
\begin{figure}[htbp]
\begin{center}
	\includegraphics[width=0.6\textwidth]{content/images/encrypted cpu}
\caption{\textbf{Encrypted CPU schematic.} This is a classic von-Neumann architecture where the memory holds both the instructions and data. Bits are represented as encrypted numbers. Reprinted from \cite[]{Brenner2011a}\label{ID_901443426}\label{figure:encrypted-cpu}\label{ID_901443426}\label{figure:encrypted-cpu}}

\end{center}
\end{figure}

Both code and data reside in the encrypted memory. This means that code and data remain secret at all times.\label{ID_1323926141}

The circuit evaluation provides \textit{obliviousness} as the entire circuit must always be solved. For example, on memory accesses each cell is reassigned -- either with its new value on a write, or an equivalent representation of its old bit value.\label{ID_818872921}
This obliviousness is an important security factor and a performance pitfall at the same time. Memory access patterns and program flow are kept secret. This however also means that access times grow with the memory size. The authors state that ``compact programs and data are the key to tolerable runtimes''. \cite[]{Brenner2012}\label{ID_1325928179}

A hardware implementation of the encrypted CPU has not yet been attempted due to various challenges such as super-wide buses and the recrypt procedure necessitated by the encryption scheme.\label{ID_1008727172}
A software implementation highlights the performance problems. Without encryption, a CPU cycle is simulated in $3 ms$. With encryption this value increases to $166 s$.\label{ID_1078829631}
\footnote{This is the measurement for the highest value of the security parameter $lambda$. Unfortunately, neither Brenner et al. nor Smart et al. \cite{Smart2010} give further details on how the security parameter relate to a comparable security level. The BSI advises a security level of $120 bit$ from the year 2022 onwards: \url{https://www.bsi.bund.de/SharedDocs/Downloads/DE/BSI/Publikationen/TechnischeRichtlinien/TR02102/BSI-TR-02102.pdf}.}\label{ID_1789113343}
Both values are obtained for $256$ memory rows -- at $13 bit$ per row this gives roughly $0.4 kB$ of memory.\footnote{A memory word contains $8 bit$ of data and a $5 bit$ command.\cite{Brenner2011}. This design decision reduces the number of costly memory access cycles.} \cite[]{Brenner2012}\label{ID_1799557031}
\subsection{Conclusion\label{ID_1939499389}}
Fully homomorphic encryption adds another tool to a cryptographer's toolbox: The ability to compute on encrypted data. The concept of an encrypted CPU builds on top of this primitive. It shows how a encrypted program with branching can be executed on encrypted data.\label{ID_1875507588}

The performance of fully homomorphic schemes is still far from being practically applicable. Through the oblivious full-circuit evaluation of the encrypted CPU this issue is amplified. However, improvements are possible on several avenues:\label{ID_607327069}
New, more efficient fully homomorphic schemes may be devised. The existing schemes can be optimised both in their algorithm and in their implementation (e.g. parallelised). Hardware implementation of the encryption, and especially the encrypted CPU also has large potential benefits.\label{ID_262947221}

Yet even a sufficiently efficient encrypted CPU could not solve secure remote computation once and for all. Firstly the computation is restricted to a single client. Without decrypting the results (in a trusted location) no communication and interaction between clients is possible. Secondly the problem of attestation is not solved by this approach.\label{ID_295590508}

\section{Trusted Computing\label{ID_360935729}\label{section:tc}}
This section defines terms important for trusted computing. These are most relevant for \autoref{chapter:tc-solutions}.\label{ID_1527667001}
\begin{description}\label{ID_1233402803}
\item[Root of trust]\label{ID_854088737}
is the sole element on which trust in a platform hinges. If the root of trust is compromised, the whole platform is compromised. \cite[]{Mitchell2005}\label{ID_1888900657}
For example, the CPU in a trusted computing setup could be the root of trust that is expected to function correctly.\label{ID_871944257}
\item[Trusted computing]\label{ID_1657615964}
is a form of secure remote computation that uses trusted hardware as the root of trust. \cite[]{Mitchell2005}\label{ID_1723503487}
\autoref{figure:trusted-computing} shows the involved components and trust relationships.\label{ID_535952528}
\item[Trusted Execution Environment (TEE)]\label{ID_261824335}
protects its assets (such as code and data) from attacks. It usually exists alongside the standard Rich Execution Environment (REE). \cite[]{GlobalPlatform}\label{ID_1872162923}
The TEE is at the very heart of a trusted computing implementation as shown in \autoref{figure:trusted-computing}. This section describes different TEE implementations.\label{ID_530801514}
\item[Trusted computing base (TCB)]\label{ID_1719015402}
is best described by the \textit{Orange Book}: The TCB ``contains all of the elements of the system responsible for supporting the security policy''. \cite[]{orangebook}\label{ID_1237482443}
This includes the root of trust, the application itself, and all intermediate software levels that have to be trusted.\label{ID_143606732}
Anything outside of the TCB does not have to be trusted.\label{ID_1731344432}
The TCB should be as small and simple as possible for the sake of security. \cite[]{orangebook}\label{ID_294862822}
Depending on the trusted computing solution the TCB may contain the operating system and/or the hypervisor.\label{ID_962329179}
\item[Software Attestation] is a two-part process. First a loaded piece of software is measured to ensure that the system is in a well-defined state. Secondly, this measurement is cryptographically signed and transmitted. This protocol can be enriched to include a key exchange. This makes it possible to securely communicate with the attested code. The process is described well in \cite{sgx-explained}.\label{ID_372928242}
\item[Data Sealing] is a process of storing data so that it can only be accessed by a component in a certain state. For example, bank account credentials could be sealed so that they can only be read by a certain operating system at a certain patch-level. \cite[]{Mitchell2005}\label{ID_708201927}

Technically, this is usually achieved through key derivation. The root of trust in a system may have a secret key. From this key, with the measurement result of software attestation, a state-specific data sealing key is derived. The data is then encrypted with this key.\label{ID_1904605343}
\end{description}\label{ID_242504118}
\begin{figure}[htbp]
\begin{center}\input{content/tikz/trusted-computing}
\caption{\textbf{Trusted computing.}\label{ID_1038375068}
The trusted execution environment is protected by trusted hardware. This introduces an additional trust relationship. Additional nodes (compared to \autoref{figure:secure-remote-computation}) are in bold font.\label{ID_1467217011}
Reprinted from\label{ID_1474157281}
 \cite[]{sgx-explained}\label{ID_1792311294}\label{figure:trusted-computing}}

\end{center}
\end{figure}


\chapter{Trusted Computing Solutions\label{ID_309872773}\label{chapter:tc-solutions}}
As explained, trusted computing is a variant of secure remote computing built on trusted hardware.\label{ID_1898011333}
This chapter first defines metrics for classifying trusted computing implementations.\label{ID_268617658}
Commercially available solutions and solutions from research are then described qualitatively.\label{ID_1980391789}
Finally, a more quantitative comparison is given in form of a table. It uses the defined metrics as the main criteria.\label{ID_1605459160}

\section{Classification\label{ID_979419236}}
The following dimensions are used to classify the solutions presented in the remainder of this section:\label{ID_1876235781}
\begin{description}\label{ID_385656837}
\item[Hardware implementation] (if present). \autoref{figure:tee} shows a variety of approaches ranging from external to on-chip solutions as defined by the GlobalPlatform alliance. \cite[]{GlobalPlatform}\label{ID_205762418}
Using hardware virtualisation techniques is a fourth option used in some solutions.\label{ID_472468399}
\item[Isolation level] at which the TEE protects the components. \autoref{figure:tee-granularity} shows the five predominant isolation levels. These levels can be observed repeatedly when evaluating the trusted computing implementations presented in this thesis.\label{ID_466621036}
\end{description}\label{ID_1293092830}
\begin{figure}[htbp]
\begin{center}\input{content/tikz/tee}
\caption{\textbf{Implementation alternatives for protecting a Trusted Execution Environment (TEE) as defined by the GlobalPlatform alliance.}\label{ID_1049041551}
The logic necessary to protect the TEE lives in nodes shaded green. It can either reside outside of the System on a Chip (SoC) as in \textit{a)}, or as a part of the regular SoC components as in \textit{c)}.\label{ID_377511617}
Reprinted from\label{ID_1243979231}
 \cite[]{GlobalPlatform}\label{ID_1516783594}\label{figure:tee}}

\end{center}
\end{figure}

\begin{figure}[htbp]
\begin{center}\input{content/tikz/tee-granularity}
\caption{\textbf{Possible levels of isolation a Trusted Execution Environment (TEE) can provide.}\label{ID_1446907066}
\textit{a)} -- \textit{e)} represent the five predominant levels in the evaluated trusted computing solutions. Virtualisation is not employed by all solutions, therefor the \textit{host operating system} and \textit{hypervisor} are printed in grey.\label{ID_1739628616}
\label{ID_1112289760}\label{figure:tee-granularity}}

\end{center}
\end{figure}


\section{Commercial\label{ID_1886048225}}
The following list of commercial trusted computing solutions gives a good overview of how the field has evolved in the past 15 years.\label{ID_642511098}
The list is not exhaustive. Instead, the chosen solutions represent noteworthy archetypes.\footnote{The most noticeable omission from this list are all kinds of cryptographic co-processors that aim to provide significant computational resources apart from the main CPUs. Any operation in excess of cryptographic primitives such as key generation and digital signatures is considered significant.} For a more extensive list, see \cite{tee_mobile_devices}.\label{ID_727374297}
\begin{description}\label{ID_838567667}
\item[2002: Trusted Platform Module (TPM)\footnotemark]\label{ID_878785835}
\footnotetext{TPM hardware first became available for the revision 1.2 of the TPM specification. This was published in 2003: \url{https://trustedcomputinggroup.org/wp-content/uploads/tpmwg-mainrev62_Part1_Design_Principles.pdf}. Later, in 2009, the TPM specification was ISO standardised: \url{https://www.iso.org/standard/50970.html}}\label{ID_1084798609}
is a separate component in a computer system that can be used for various cryptographic and attestation tasks. \cite[]{tcg:tpm2-arch}\label{ID_409429025}
It can be classified as a external secure element (\autoref{figure:tee}) that can -- with different means -- provide a variety of isolation levels (\autoref{figure:tee-granularity}).\label{ID_1604168991}
The TPM must maintain a separate state which cannot be tampered with. For this reason, TPMs are usually dedicated hardware chips.\footnotemark\label{ID_461477657}
\footnotetext{\cite{Raj2015} describes a software TPM implementation using TrustZone. The TPM state is protected in the secure world.}\label{ID_1882630870}
A TPM has an embedded secret key used to sign its outputs, e.g. when supplying system measurements. This secret key is certified by the manufacturer to establish its authenticity. \cite[]{tcg:tpm1-design}\label{ID_34222075}

TPMs can be used to measure the state of the entire system. This can be done in a \textit{static} fashion, starting from the boot loader, as shown in \autoref{figure:tpm-measurement}. The TPM can also provide a \textit{dynamic} measurement. This is done when software such as a hypervisor is elevated into a super-privileged virtual machine management (VMM) mode.\label{ID_1669235821}
Performing a dynamic measurement requires CPU support.\footnote{The technologies of the two major vendors are Intel TXT and AMD SVM.}\label{ID_447984718}
See \autoref{section:tc-research} for details on how TPMs can also be used to provide isolation for components on levels smaller than the virtualisation stack layer (\textit{a-b} in \autoref{figure:tee-granularity}).\label{ID_300626990}
\begin{figure}[htbp]
\begin{center}\input{content/tikz/tpm-measurement}
\caption{\textbf{Static system state measurement using a Trusted Platform Module (TPM).}\label{ID_734095868}
The TPM stores the measurement in a register (register values are shaded orange).\label{ID_333225320}
At reboot, the measurement register is reset to zero. Then "the software at every boot stage hashes the next boot stage".\cite{sgx-explained}\label{ID_1944654012}
This hash is sent to the TPM, which updates the measurement register by hashing both the old register value and new measurement.\label{ID_1908069125}
Reprinted from\label{ID_1280723034}
 \cite[]{sgx-explained}\label{ID_1826130514}\label{figure:tpm-measurement}}

\end{center}
\end{figure}

TPMs are not ideally suited for securing individual applications:\label{ID_1726205291}
\begin{itemize}\label{ID_1105301170}
\item TPMs do not isolate processes. Apart from trusted cryptographic functions they only provide a measurement of a software state. Isolation must be implemented in software. This is susceptible to privilege escalation. Also, this is an additional development and/or maintenance overhead.\label{ID_1644282989}
\item System components that must be trusted include the system bus and main memory. \cite[]{virgtech:tpm}\label{ID_1065555148}
A TPM can therefore not protect secrets from any party that has hardware access, and might e.g. read main memory.\label{ID_788700023}
\end{itemize}\label{ID_244995283}
\item[2003: ARM TrustZone\footnotemark]\label{ID_1887577967}
\footnotetext{\url{https://www.arm.com/about/newsroom/3791.php}}\label{ID_1026997187}
is an optional extension to the ARM CPU specification.\label{ID_608180135}
It can be classified as a processor secure environment (\autoref{figure:tee}) that provides isolation at the application level (\autoref{figure:tee-granularity}).\label{ID_1608998276}
A TrustZone-capable system can be described as having a split personality. It runs in either the normal world or the secure world, indicated by an extra bit on the system bus. \cite[]{trustzone}\label{ID_1335311105}
Other hardware components use this bit to implement access restrictions. For example the memory management unit does not allow access to pages that belong to the secure world while running in the normal world.\label{ID_472129216}
A special instruction, the \textit{secure monitor call}, lets the system switch worlds by executing the monitor code which was defined during system startup.\label{ID_983944221}

The distinction between normal and secure world is orthogonal to the regular privilege levels (user and kernel mode) as shown in \autoref{figure:trustzone}.\label{ID_1080183818}
\begin{figure}[htbp]
\begin{center}\input{content/tikz/trustzone}
\caption{\textbf{Example secure world implementation using ARM TrustZone technology.}\label{ID_1321130825}
The system boots in secure mode and a monitor is registered which acts as the interface between secure and normal world. The secure word has its own kernel which must handle process isolation. Applications in the normal world can indirectly access services in the secure world through a \textit{secure monitor call}.\label{ID_1221506439}
Reprinted as a simplified version from\label{ID_1183892692}
 \cite[]{trustzone}\label{ID_510061380}\label{figure:trustzone}}

\end{center}
\end{figure}


The figure also shows that interrupts are first handled by the monitor. Devices can thus be mapped to either of the two worlds, or both. If a device, e.g. a keyboard, is mapped to the secure world it is possible to provide trusted input that cannot be tampered with by the normal world. If a device is mapped to both worlds (such as main memory) then the device controller must enforce the access restrictions (e.g. by keeping track of which world a memory page is assigned to via the page table).\label{ID_139905209}

TrustZone is a very flexible hardware concept. In its documentation, ARM proposes to implement two worlds with separate kernels.\label{ID_1914471494}
Samsung Knox on Android phones is a good example. Knox provides attestation capabilities and sets up an isolated workspace environment, which is completely separated from the regular environment. \cite[]{knox}\label{ID_251460704}
As the hardware imposes no limits on how it is used, it is also possible to implement deviating concepts such as a firmware TPM. \cite[]{Raj2015}\label{ID_126730563}

Attestation is not part of the TrustZone specification. However , approaches such as the firmware TPM show that this concept is easy to implement using TrustZone. The hardware root of trust is present. All that is needed in addition is a secret key only accessible by the secure world.\label{ID_1549018417}
TrustZone is -- by itself -- not strictly a trusted computing solution as a remote party cannot verify the state of the secure world. It is still included in this list because it can serve as a hardware basis to implement fully-fledged trusted computing solutions.\label{ID_725637120}

While TrustZone is flexible, it is not ideally suited for securing applications in a general fashion due to the following reasons:\label{ID_1692861456}
\begin{itemize}\label{ID_1485312254}
\item TrustZone isolates worlds, but not processes within the secure world. All applications that should be protected live together in the secure world. It is solely the responsibility of the Kernel to isolate the processes in the secure world. The data in the secure world is thus susceptible to be compromised via privilege escalation of the secure kernel.\label{ID_689096711}
\item To isolate applications on TrustZone hardware, a monitor and secure kernel are needed. This is additional development overhead (or at least maintenance overhead\footnote{\url{https://github.com/ARM-software/arm-trusted-firmware }}).\label{ID_179390539}
\item The TCB is far larger than the security critical parts of the application that should be hardened. It includes the boot loader, monitor, secure kernel and all other applications running in the secure world.\label{ID_1738797352}
\end{itemize}\label{ID_1374620071}
\item[2015: Intel SGX\footnotemark]\label{ID_1054190841}
\footnotetext{\url{https://software.intel.com/en-us/sgx}}\label{ID_229356089}
is an instruction set extension with which protected memory regions, called enclaves, can be set up.\label{ID_61266204}
An enclave is a TEE for a single software module.\label{ID_578161669}
It can be classified as a processor secure environment (\autoref{figure:tee}) that provides isolation at the module level (\autoref{figure:tee-granularity}).\label{ID_1140603591}
It is orthogonal to existing protection mechanisms such as virtual memory or privilege levels.\label{ID_712206334}
Enclaves are protected from any external access not allowed by their interface definition, be it by the operating system or an administrator with hardware access. \cite[]{McKeen2013}\label{ID_1686776308}
Like a TPM, an SGX-enabled CPU has an embedded secret key so it can provide signed measurements of an enclave's state to third parties. \cite[]{c}\label{ID_1516650013}
SGX is explained in more detail in \autoref{chapter:sgx}.\label{ID_877492617}

SGX is well-suited to secure applications:\label{ID_98041302}
\begin{itemize}\label{ID_1198060032}
\item SGX isolates at the module level. The TCB consists of only the module code.\label{ID_1985518136}
\item No hardware apart from the CPU must be trusted. Memory is encrypted when stored in RAM.\label{ID_784477812}
\end{itemize}\label{ID_976583741}
\item[2016: Windows Isolated User Mode (IUM)\footnotemark]\label{ID_475389692}
\footnotetext{\url{https://msdn.microsoft.com/en-us/library/windows/desktop/mt809132(v=vs.85).aspx}}\label{ID_116366543}
is a secure execution mode similar to the secure world in TrustZone.\label{ID_1711941438}
It uses virtualisation (not shown in \autoref{figure:tee}) and provides isolation at the application level (\autoref{figure:tee-granularity}).\label{ID_935453675}
The kernel and processes in secure mode are separated from normal mode by the Hyper-V hypervisor.\footnote{\url{https://channel9.msdn.com/Blogs/Seth-Juarez/Isolated-User-Mode-in-Windows-10-with-Dave-Probert }}\label{ID_1602001478}
Unlike TrustZone and the other technologies in this list, IUM is implemented in software -- not considering CPU virtualisation support.\label{ID_1070749392}
IUM is used to secure credentials in the Windows Credential Guard.\footnote{\url{https://docs.microsoft.com/en-us/windows/access-protection/credential-guard/credential-guard}}.\label{ID_1423103777}

IUM has limited potential for securing applications:\label{ID_642451187}
\begin{itemize}\label{ID_214143695}
\item The TCB size is large. It includes the hypervisor, secure kernel and application.\label{ID_239128518}
\item Data in the isolated mode can be compromised via privilege escalation of the secure kernel.\label{ID_1471146382}
\item Microsoft has not yet published any information on how to develop applications for IUM. It seems that for now it is used for internal Windows functionality such as Credential Guard only.\label{ID_1314168201}
\item As a software-only solution, no hardware root of trust is present. Windows IUM does not provide attestation. Strictly speaking it does not match the definition of trusted computing used in this thesis. IUM is still listed, as it is comparable to many of the solutions from research.\label{ID_1504627143}
\end{itemize}\label{ID_1993992542}
\end{description}\label{ID_412101102}

\section{Research\label{ID_1218417925}\label{section:tc-research}}
Trusted computing solutions from the research community are now introduced in detail.\label{ID_1414676979}
Where possible, similarities to the commercial solutions are pointed out.\label{ID_837800524}
The solutions are grouped by isolation level (\autoref{figure:tee-granularity}).\label{ID_1121208378}
The order of the following solutions is the same as in \autoref{table:tc-comparison}, which gives a high-level comparison.\label{ID_1270744760}
\subsection{Module Isolation\label{ID_833475083}}
\begin{description}\label{ID_845705882}
\item[Sanctum\cite{Costan}]\label{ID_50257265}
Sanctum is comparable to Intel SGX in both implementation and features. As the authors themselves state, it ``draws heavy inspiration'' from SGX. It was designed by Costan and Devadas, who also reverse-engineered and documented many details of SGX. \cite[]{sgx-explained}\label{ID_916368692}
Sanctum tries to improve on SGX. It protects against software attacks that analyse a program's memory access patterns.\label{ID_1386160732}

The implementation is less invasive than SGX, as it only ``adds hardware at the interfaces between building blocks'' instead of modifying them directly.\label{ID_808280017}
Sanctum isolates enclaves by virtually partitioning the DRAM into ``regions that use disjoint Last Level Cache (LLC) sets.'' The page walker then enforces the access rules as known from SGX.\label{ID_1748783794}

The hardware additions are complemented by a security monitor. It is small enough to be formally verified. The monitor is responsible for handling ``DRAM region allocation and enclave management'' and protects sensitive registers. \cite[]{Costan}\label{ID_1617987140}

Without going into too much detail, \autoref{figure:sanctum-state} shows how similar Sanctum's enclave and thread management are to SGX.\label{ID_1825665924}
\begin{figure}[htbp]
\begin{center}\input{content/tikz/sanctum-state}
\caption{\textbf{State diagrams for enclave and thread state in Sanctum.}\label{ID_1455628057}
The states and transitions are very similar to those in SGX since Sanctum's design was largely inspired by SGX.\label{ID_388325382}
Reprinted from\label{ID_615159607}
 \cite[]{Costan}\label{ID_486639489}\label{figure:sanctum-state}}

\end{center}
\end{figure}

\item[TrustZone Trusted Language Runtime (TLR)\cite{Santos2014}]\label{ID_1712498850}
implements a .NET runtime that is isolated in TrustZone's secure world. Security critical parts of an application can be extracted into ``trustlets'' (similar to enclaves in SGX) which are executed within the TLR.\label{ID_843781337}

Apart from TrustZone as hardware the TCB includes the TLR implementation. As with all solutions with a software TCB at level \textit{c} or broader, TLR is susceptible to privilege escalation if the TLR is compromised.\label{ID_456338807}

Though TrustZone could support trusted I/O, this feature is not available in the TLR, as it would require adding drivers to the TCB.\label{ID_813431600}
TLR does not provide attestation. A remote party cannot verify the state of trustlets and the runtime it is interacting with. Thus, TLR does not strictly match the definition of trusted computing used in this thesis. It is listed as its implementation is interesting and comparable to other solutions.\label{ID_1734052719}
\item[Oasis\cite{Owusu2013}]\label{ID_1097915963}
is comparable to SGX but avoids encrypting memory in DRAM.\label{ID_1149911880}
The concept hinges on using caches as RAM so that secrets never leave the CPU, e.g. are never stored on DRAM.\label{ID_479354751}
To this end, Oasis adds a set of CPU instructions to ``enable an isolated execution environment contained entirely on chip''.\label{ID_269399808}
As the authors themselves remark, Oasis is inferior to SGX in that it only supports applications of a very limited size.\label{ID_1544780564}
\item[Fides\cite{Strackx2012}]\label{ID_1573635887}
uses a ``small dynamic hypervisor to isolate [enclaves]'' from the rest of the system. The hypervisor separates two virtual machines (VMs): the legacy and secure VM, similar to TrustZone.\label{ID_99725932}
A minimal secure kernel isolates the different enclaves (called ``self protecting module (SPM)'') in the secure world.\label{ID_1045769233}

The software TCB includes the hypervisor and secure kernel.\label{ID_1212833812}
A TPM is used to attest the hypervisor and security kernel state.\label{ID_391511184}
The legacy kernel is excluded from the TCB. The ``running legacy kernel is pulled in the legacy VM, and memory access control of both VMs is configured''. This is possible using the dynamic TPM measurement features.\label{ID_1472841998}

Attestation and data sealing are only available on the basic TPM level, which is bound to the overall system state. This means the hypervisor and secure kernel can be attested, and data can be sealed to this state. This cannot be done for individual modules.\label{ID_577386957}
\item[TrustVisor\cite{McCune2010}]\label{ID_1338218613}
was developed by the authors of Flicker, with the goal of improving performance.\label{ID_1509697723}
It avoids slow TPM calls on the critical path by providing a virtual micro-TPM to each enclave (called ``piece of application logic (PAL)''). With this micro-TPM, each enclave can be attested and perform data sealing.\label{ID_448665960}

The micro-TPMs are hosted by a trusted hypervisor, which is dynamically loaded and measured (as done by Fides).\label{ID_488141781}
Thus the software TCB includes the hypervisor. The chain of trust when validating an enclave attestation is rooted in the TPM measurement. The chain thus includes the enclave, the micro-TPM and the hypervisor.\label{ID_1898494666}

Unlike Fides, there is no secure kernel that isolates enclaves. This behaviour is emulated on a lower level by un-mapping enclave pages from the legacy operating system. Each enclave has its own virtual guest memory. \autoref{table:tc-comparison} shows the software TCB as \textit{d}, when really it only includes the hypervisor and enclave, but no operating system.\label{ID_708049480}
\item[Flicker\cite{McCune2008}]\label{ID_878060233}
enables fine-grained attestation and isolation of enclaves using only the dynamic attestation feature of a TPM and a supported CPU.\label{ID_445599816}

The intended use of the dynamic TPM measurement is to virtualise an untrusted operating system after booting it and lazily loading a privileged hypervisor (as described for Fides).\label{ID_1988839866}
To do so, the CPU enters a special execution mode to load the hypervisor with elevated privileges. During this time the legacy operating system is suspended. Its privileges are demoted to VM guest privileges. This way the untrusted operating system is effectively removed from the TCB.\label{ID_670518178}

Instead of loading a hypervisor Flicker executes the enclave during this special loading phase, which is called a ``Flicker session''.\label{ID_827948010}
This session is also measured. After a cleanup phase (e.g. caches) regular execution is resumed and the result is returned.\label{ID_1543044077}

This approach is nearly feature complete with regards to \autoref{table:tc-comparison}. It isolates enclaves on the same level as SGX. The hardware TCB only includes the TPM. The software TCB includes the enclave and only a small additional wrapper for handling parameter input/output and cleanup.\label{ID_504952060}

The main drawback of the approach is the performance. Slow TPM operations are on the critical execution path -- they are executed every time the enclave is executed.\label{ID_2022441}
Only one core is used and interrupts are disabled in the special CPU state. Thus the system is stalled for the duration of a Flicker session. For use in interactive systems, Flicker enclaves need to exhibit a very small runtime. This is diametrically opposed to TPM overhead incurred with each session.\label{ID_1920950472}
Only one Flicker session can be executed at any given point in time, as the special CPU mode is not intended for parallel use.\label{ID_466004716}

In summary, despite the apparent features and small TCB, Flicker is not well-suited for general-purpose applications due to its performance limitations.\label{ID_1094537554}
\end{description}\label{ID_294304177}
\subsection{Application Isolation\label{ID_94612974}}
\begin{description}\label{ID_82011801}
\item[Microsoft Haven\cite{Baumann2014}]\label{ID_353301403}
uses SGX to isolate an entire legacy application within an enclave.\label{ID_97042978}
Along with the application, a library operating system (Drawbridge LibOS\footnote{\url{https://www.microsoft.com/en-us/research/project/drawbridge/}}) is included in the enclave.\label{ID_1807131257}
``Drawbridge LibOS is a version of Windows 8 refactored to run as a set of libraries within the picoprocess.''\footnote{A picoprocess can interact with the operating system only through a very narrow system call interface. This is similar to the system call interface that hardware VMs use.}\label{ID_465258009}

An additional shield module within the enclave mediates between the library operating system and the outside world (untrusted runtime).\label{ID_1475060210}
Any system call by the application is passed through the library operating system, secured by the shield module, and only then passed on through the untrusted runtime on to the untrusted operating system. The layers are depicted in \autoref{figure:haven}.\label{ID_1924838776}
This approach is re-visited in \autoref{section:sgx-hardening} in the context of SCONE.\label{ID_1989885067}
\begin{figure}[htbp]
\begin{center}\input{content/tikz/haven}
\caption{\textbf{Architecture of Microsoft Haven.}\label{ID_186584288}
The enclave isolates the entire unmodified application as well as a library operating system.\label{ID_1502290495}
Together with the shield module this protects the application from attacks by a malicious operating system.\label{ID_524857908}
The enclave interacts with the host kernel through a the narrow picoprocess API, as the library operating system abstracts from higher-level system calls.\label{ID_1865559949}
The untrusted wrapper only passes on calls from and to the enclave.\label{ID_1698784106}
Reprinted as a simplified version of\label{ID_1354023484}
 \cite[]{Baumann2014}\label{ID_1468585962}\label{figure:haven}}

\end{center}
\end{figure}


Haven re-purposes SGX in a fashion. SGX was designed to isolate small security-critical parts of an application inside individual enclaves.\label{ID_679922183}
This keeps the TCB small and can help when reasoning about security of the application.\label{ID_158610913}
Haven tries to find a different solution to secure unmodified legacy applications.\label{ID_1158551044}

This dramatically increases the size of the TCB but also provides additional benefits.\label{ID_967837581}
The application must not be refactored or modified.\label{ID_40595564}
In addition it protects against so-called Iago attacks by the operating system. A Iago attacks exploits the fact that an application may rely on a system call to be correctly executed instead of validating the results.\label{ID_810626140}

Haven is dated to 2014 and requires SGX, which is dated to 2015. Haven was implemented using SGX simulations and pre-release hardware before SGX-enabled CPUs became generally available.\label{ID_775639108}
\item[Minibox\cite{Li2014}]\label{ID_1759565280}
is comparable to TrustVisor, as it multiplexes the TPM into several virtual micro-TPMs.\label{ID_708706069}
Minibox has a slightly different focus, as it aims to be a ``two-way sandbox''.\label{ID_1073668755}
Traditional sandboxing protects the execution environment, e.g. the operating system, from malicious applications.\label{ID_1512132230}
Minibox protects both the operating system and the application.\label{ID_686729196}
Minibox executes applications in an isolated environment, called ``Mutually Isolated Execution Environment (MIEE)''.\label{ID_1462001648}

A hypervisor provides isolation and the micro-TPMs. It is included in the TCB.\label{ID_44939342}
The micro-TPMs enable data sealing and attestation on a per-application basis.\label{ID_1229123325}
A shield module in between checks and sanitises interaction in both directions.\label{ID_71322980}
\item[InkTag\cite{Hofmann2013}]\label{ID_1193381543}
isolates applications in the same way as many other solutions in this section: through virtualisation. This is similar to Windows IUM.\label{ID_330168128}
A hypervisor isolates the application, called ``high-assurance process (HAP)'', from the operating system.\label{ID_751005955}
The hypervisor provides ``secure files'', which can be seen as a form of data sealing.\label{ID_1357961035}

InkTag does not provide attestation, so a remote user cannot verify the state of the system.\label{ID_705281429}
With regards to the definition used in this thesis, it is therefor not strictly a trusted computing solution. Technically, it is interesting and comparable to other solutions and thus listed.\label{ID_643772456}

A distinguishing feature of InkTag is its ``para-verification''. The InkTag hypervisor verifies the behaviour of the operating system. HAPs can check the verification status using hypercalls.\label{ID_192984381}
To keep verification simple, InkTag requires the untrusted operating system to assist the hypervisor in its own verification.\label{ID_1553347413}

Another interesting aspect is how isolation is technically achieved.\label{ID_152315504}
InkTag does not rely on memory address translation as a hardware feature alone to isolate an HAPs memory.\label{ID_1866963112}
Instead, the hypervisor encrypts and hashes a HAPs memory pages on a context switch back to the operating system. This is somewhat comparable to SGX, where pages in DRAM are also encrypted.\label{ID_984786854}
To describe it in the author's words: ``InkTag uses hardware [memory management unit (MMU)] virtualisation for coarse-grained separation between secure and insecure data. Then it uses software only when needed, to manage the userspace portions of HAP page tables.''\label{ID_1124935151}
\item[Overshadow\cite{Chen2008}]\label{ID_1400272883}
is comparable to InkTag. A hypervisor isolates applications. The implementation differs.\label{ID_869320852}
Overshadow uses the terms ``shadowing'' and ``cloaking''. Memory is dynamically encrypted (cloaked) by the hypervisor depending on the ``shadow context'' accessing it.\label{ID_1595335407}
Only a cloaked application can read its own memory in decrypted form.\label{ID_213890862}

The hypervisor intercepts some system calls instead of passing them on to the untrusted operating system, such as file input and output.\label{ID_827784046}
Files accessed by applications are memory-mapped. With the cloaking mechanism in place they are thus automatically encrypted when written to disk.\label{ID_94227936}

The idea of transparently encrypting file input/output is similar to Haven, where unmodified applications are protected.\label{ID_1071753091}
Overshadow also tries to set a low adoption barrier by minimising necessary changes to legacy applications.\label{ID_5677792}

The hypervisor has a single secret key which it uses for memory encryption. The key is also used to e.g. protect file metadata integrity when written to disk.\label{ID_829303655}
This is somewhat similar to the memory integrity protection performed by SGX.\label{ID_1477727792}
However, SGX derives a unique key for every enclave (or enclave author).\label{ID_881038647}
The file encryption in Overshadow cannot be counted as data sealing, as the data is not sealed to a specific application but encrypted with the ``global'' hypervisor key.\label{ID_1562148172}

Like InkTag, Overshadow does not provide attestation and is, strictly speaking, not a trusted computing solution.\label{ID_436671458}
\end{description}\label{ID_1545531597}
\subsection{Operating System Isolation\label{ID_1279358890}}
\begin{description}\label{ID_1149112575}
\item[CloudVisor\cite{Zhang2011}]\label{ID_1588951554}
provides trusted VMs.\label{ID_1095393821}
VMs are an established deployment level in cloud environments.\label{ID_44643707}
Users typically trust the cloud provider to execute a VM properly and properly isolate it from other VMs. This trust is not technologically grounded.\label{ID_96896603}

CloudVisor provides trusted VMs based on two factors.\label{ID_661635791}
Firstly, VMs are protected from the hypervisor. This is implemented through nested virtualisation. A small security hypervisor in host mode controls the actual hypervisor.\label{ID_514198549}
The security hypervisor is comparably small. It is dynamically loaded and attested through the TPM. It thus does not contain boot loader code. This reduces the size of the TCB.\label{ID_926319613}
Secondly, the state of the security hypervisor can be remotely attested. A TPM is used for this. A user can then choose to release a VM image decryption key only to an attested hypervisor.\label{ID_175981473}

As for all trusted computing solutions that isolate on the virtualisation layer, the attack surface is large. If the guest operating system in a VM is compromised, all sensitive applications in that VM are compromised. Privilege escalation is also an issue.\label{ID_1893397931}
Also, CloudVisor does not protect against hardware attacks. Any party with hardware access can read the non-encrypted memory from DRAM (by tapping into the memory bus).\label{ID_791021042}

CloudVisor transparently inputs disk input/output.\label{ID_1740019798}
The data is not sealed to the VM state, but encrypted with a user-defined key.\label{ID_203575878}
Only the hypervisor state can be attested, not the state of an individual VM.\label{ID_1959689941}
\item[Nova\cite{Steinberg2010}]\label{ID_61001884}
is a micro-hypervisor, implemented from scratch.\label{ID_1979954588}
Using the same design principals as for micro-kernels, the Nova hypervisor is highly modularised.\label{ID_1097579055}
Its design follows the principle of least privilege.\label{ID_786963966}
Only the bare minimum of Nova runs at the super-privileged VMM kernel level.\label{ID_844682668}

Nova is not a trusted computing solution. However, it showcases the principle of least privilege. This should be kept in mind when developing applications from Intel SGX.\label{ID_1949063731}
\item[NoHype\cite{Keller2010}]\label{ID_399891803}
provides virtualisation without a hypervisor.\label{ID_1982528190}
Instead, resources are statically allocated: Each VM is allocated one CPU core and a slice of memory.\label{ID_1103417020}
However, VM management must still take place.\label{ID_460072436}
NoHype uses a management VM to load, start and stop other VMs.\label{ID_1653231210}
During execution, no interaction with a hypervisor is necessary.\label{ID_78679497}

NoHype does not run on standard hardware. It requires additional hardware virtualisation features that no CPU currently offers.\label{ID_1042436161}
NoHype limits a guest VM to a single core. It can parallelise across VMs, but not within VMs.\label{ID_1868828851}

NoHype addresses VM isolation, but no further features such as data sealing or attestation. As attestation is not provided, NoHype is not a trusted computing solution as defined in this thesis. It is still listed due to its interesting approach.\label{ID_1659320949}
\item[vTPM\cite{Perez2006}]\label{ID_253555451}
provides a virtual TPM to each VM.\label{ID_771624481}
This TPM is designed to match the VM life cycle. It can be stored, loaded and migrated with its VM.\label{ID_330974310}
The VM attestation provided by a virtual TPM is a compound attestation. The virtual TPM attests the VM. The hardware TPM attests the hypervisor and boot process.\label{ID_1083096548}

TrustVisor and Minibox provide virtual TPMs at the module and application level. vTPM provides virtual TPMs at the VM level.\label{ID_202468909}

An interesting aspect is how migration is enabled. The virtual TPMs have to be linked to the hardware TPM so that the process is rooted in a hardware root of trust.\label{ID_555144421}
If implemented naively, this would preempt the ability to later on migrate a virtual TPM to a different machine with a different hardware TPM.\label{ID_1205234476}
vTPM solves this using migrate-able TPM storage keys, which the TPM standard defines.\label{ID_964255737}
\item[Terra\cite{Garfinkel2003}]\label{ID_931924935}
is the first hypervisor-based solution for trusted computing.\label{ID_1552017657}
It introduced the idea of using a trusted hypervisor to isolate individual VMs.\label{ID_744934551}
In its design, Terra -- like vTPM -- uses a hardware device for data sealing and attestation.\label{ID_1233067999}
It then exposes these features to every VM.\label{ID_570557425}
The Terra prototype does not actually include such a hardware device. The authors identify a TPM as a good candidate.\label{ID_1769638002}
\end{description}\label{ID_1381661910}

\section{Comparison\label{ID_995120664}}
\autoref{table:tc-comparison} shows a comparison of all trusted computing solutions presented so far.\label{ID_31031823}
The table groups solutions by the TEE level they expose. Solutions with TEE level \textit{a} allow the developer to isolate separate modules of his application.\label{ID_1205678557}
The narrower the TEE level of isolation is, the smaller the isolated parts can be. This makes them easier to verify and less likely to contain security bugs.\label{ID_1993411071}

\begin{table}
\centering
\begin{threeparttable}
% exported from LibreOffice using Calc2Latex extension macro
\input{content/tables/tc-comparison}
\caption{
\textbf{Comparison of trusted computing solutions.}\label{ID_1431047162}
Rows are ordered first by \textit{Trusted Execution (TEE) Level}, then by \textit{Year}. The columns \textit{TEE Level} and \textit{Software Trusted Computing Base (TCB)} refer to \autoref{figure:tee-granularity}.\label{ID_1895412115}
All commercial solutions can be used stand-alone (shown in their own row). Most commercial solutions are also used as hardware foundation by solutions from research (shown in the \textit{Hardware TCB} column).\label{ID_1108934633}
Solutions that do not support attestation cannot strictly be considered implementations of trusted computing. They do not support the verification step in \autoref{figure:trusted-computing}.\label{ID_946982666}
}
\label{table:tc-comparison}\label{ID_925340590}
\begin{tablenotes}\label{ID_1070677592}
\item[a] The software levels a developer must provide to use the solution. E.g. \textit{c} means that an operating system and the application must be provided. This value of this column is automatically the lower bound for the value of \textit{Software TCB}.\label{ID_429242638}
\item[b] The software levels that are included in the solution's TCB. E.g. \textit{d} means the entire virtualisation stack is included in the TCB. The software TCB is the union of software levels that the solution internally adds and the software levels the developer must add (\textit{TEE Level}).\label{ID_1226934143}
\item[c] \textit{Virt.} stands for hardware virtualisation support. \textit{SGX, TrustZone, TPM} refer to the respective commercial solutions.\label{ID_1945080258}
\end{tablenotes}\label{ID_1977590267}
\end{threeparttable}
\end{table}
The TEE level controls the flexibility and ease of adoption.\label{ID_1265116413}
A broader TEE level may be more insecure, but can facilitate re-use of unmodified VMs or applications.\label{ID_726502290}
Potentially, solutions higher up in the table can also emulate broader TEE levels.\label{ID_409119986}
Haven shows how SGX, which isolates at module level, can be used to isolate an entire application including a library operating system.\label{ID_1577048947}

Most solutions expose a narrow TEE level at the cost of a larger software TCB. TLR includes the secure kernel and .NET language runtime. Fides and TrustVisor include a hypervisor.\label{ID_289926468}
Such a large software TCB is required when the underlying hardware does not support isolation at the desired level. Solutions with a smaller software TCB require specialised hardware. This usually means a larger hardware TCB.\label{ID_7381152}
Shifting the TCB from software into hardware is not necessarily an improvement. Firstly, it is hard to draw a clear line between the two. SGX is considered a hardware feature, but is implemented mostly in micro-code, the firmware of the CPU. \cite[]{sgx-explained}\label{ID_135747553}
Secondly, a hardware implementation must not automatically be more secure than the alternative in software.\label{ID_1373303945}

All presented solutions utilise the CPUs processing power. A TPM is used as an external secure element by some. This is only responsible for attestation and handling of cryptographic keys.\label{ID_1726004639}
Some solutions such as Flicker and NoHype do not make full use of the CPUs processing power.\label{ID_1646772907}

This is to the author's knowledge the first comparison of its kind.\label{ID_122305244}
A comparison of security features of some solutions is presented in \cite{sgx-explained}.\label{ID_842412303}

\chapter{Intel SGX\label{ID_1888222908}\label{chapter:sgx}}
This chapter describes Intel SGX in more detail. Costan et al. provide an exhaustive, in-depth description and analysis of SGX which is referred to as additional reading material. \cite[]{sgx-explained}\label{ID_870693712}
This chapter briefly describes the basic concepts of SGX and then summarises further findings from research.\label{ID_147500482}
This includes performance studies, known criticism and security issues, as well as noteworthy applications built on top of SGX.\label{ID_1316984123}

\section{Overview\label{ID_1052911477}}
Intel SGX is a trusted computing solution. It is fully contained within the CPU and is exposed as an instruction set.\label{ID_1548132428}
As described in \autoref{chapter:tc-solutions}, SGX protects individual software modules in so-called ``enclaves''.\label{ID_884480539}
Compared to other solutions, the TCB is small. It includes only the protected module and the CPU.\label{ID_1231030834}
SGX allows remote parties to verify the state of an enclave (attestation). It provides additional features, such as data sealing, on top.\label{ID_529967846}

The operating system, system management code and other parts of the application do not have to be trusted.\label{ID_1978585841}
The enclave is also protected from code running in system management mode (SMM), as well as from direct memory access (DMA). \cite[]{McKeen2013}\label{ID_508054107}
SGX changes the memory access semantics by introducing a protection scheme inverse to the existing privilege levels.\cite[ch. 6.2]{sgx-explained}. \autoref{figure:sgx-privilege} shows how enclaves relate to existing privilege levels.\label{ID_607406159}
\begin{figure}[htbp]
\begin{center}\input{content/tikz/sgx-privilege}
\caption{\textbf{Intel SGX enclave within the privilege level hierarchy.}\label{ID_1009832582}
An Intel CPU typically has two privilege schemes.\label{ID_135134113}
Privilege rings are the oldest concept, of which nowadays only ring zero and three are used to separate the operating system and applications. These are often called kernel and user mode.\label{ID_1292196585}
Virtualisation support adds another privilege scheme. The hypervisor runs in VMX root mode. It is protected from the guest VMs running in VMX non-root mode. The BIOS runs at the highest privilege level in system management mode (SMM).\label{ID_394725974}
SGX enclave mode adds an inverse isolation layer. The two existing privilege schemes protect more privileged components (bottom) from less privileged ones (top). SGX enclaves are in the least privileged layer, but are protected from all more privileged components.\label{ID_1068699047}
Reprinted from\label{ID_807064713}
 \cite[]{sgx-explained}\label{ID_1516228733}\label{figure:sgx-privilege}}

\end{center}
\end{figure}


\autoref{figure:sgx-address-space} shows an abstract view of an application's address space layout.\label{ID_1645584733}
The enclave's memory is protected by the CPU from direct access by any component but the enclave.\label{ID_1772616683}
When enclave memory is loaded into the CPU (caches), the CPU can enforce isolation by checking whether it is currently executing code of the correct enclave.\label{ID_1309432999}
If a memory page leaves the control of the CPU (when writing it to DRAM) it is encrypted and integrity-protected. \cite[]{Gueron}\label{ID_308074010}
More details on SGX's memory management are given in \autoref{section:sgx-perf}.\label{ID_879539859}
\begin{figure}[htbp]
\begin{center}\input{content/tikz/sgx-address-space}
\caption{\textbf{Application address space with an Intel SGX enclave.}\label{ID_1596894882}
The CPU only allows access to the enclave's memory if it is currently executing code belonging to that very same enclave.\label{ID_811510196}
An enclave can be entered only at specific points in the code, defined in the entry table.\label{ID_1407494566}
The entire enclave memory (including code and entry table) is measured when the enclave is initialised. The CPU can attest to a remote party that it loaded the enclave correctly.\label{ID_1200889569}
Reprinted from\label{ID_1311428979}
 \cite[]{McKeen2013}\label{ID_1518668474}\label{figure:sgx-address-space}}

\end{center}
\end{figure}


An interesting aspect of SGX is that it relies on the untrusted operating system to perform its regular management tasks such as scheduling and memory allocation.\label{ID_96634994}
This includes the steps for setting up an enclave.\label{ID_307359552}
Enclave attestation would expose any attempts by a malicious operating system to load a tainted enclave.\label{ID_483221956}
\autoref{figure:sgx-enclave-life-cycle} shows the enclave life cycle.\label{ID_1080928863}
\begin{figure}[htbp]
\begin{center}\input{content/tikz/sgx-enclave-life-cycle}
\caption{\textbf{Intel SGX enclave life cycle.}\label{ID_1610889698}
The state transitions occur when CPU instructions are executed. E.g. \textit{ECREATE} creates a new, uninitialised enclave.\label{ID_805562591}
The operating system is expected to load the enclave by adding pages and extending the measurement of the enclave (similar to TPM measurement in \autoref{figure:tpm-measurement}).\label{ID_244657479}
Once \textit{EINIT} is called, the enclave is locked down. Its measurement is final and does not change when the enclave executes and changes internal data. The OS can no longer access the enclave's memory pages.\label{ID_1399476685}
The enclave can now only be entered via \textit{EENTER} (and after interrupts through \textit{ERESUME}) at locations defined in the entry table.\label{ID_98268923}
\textit{EGETKEY} and \textit{EGETREPORT} use the initial measurement (the enclave's \textit{identity}) for attestation and to derive cryptographic keys data sealing.\label{ID_1969992855}
The \textit{page management instructions} refer to paging into and out of Enclave Page Cache (EPC), a special memory area.\label{ID_1496257738}
Reprinted as a simplified version from\label{ID_1060342788}
 \cite[]{sgx-explained}\label{ID_538890645}\label{figure:sgx-enclave-life-cycle}}

\end{center}
\end{figure}

This reliance on the untrusted operating system keeps the SGX implementation small. It does however open up certain attack avenues. A denial of service (DoS) attack is straight-forward, as the operating system can refuse to schedule any enclave threads. In the context of remote computation, the infrastructure owner could choose to cut the power at any time, so this is not really a disadvantage.\label{ID_1767974666}
More serious security issues are described in \autoref{section:sgx-criticism}.\label{ID_1234909125}

Each SGX CPU has an embedded cryptographic private key.\label{ID_85719808}
Using a special group signature scheme, the CPU uses this key to attest the state of an enclave. \cite[]{c}\label{ID_779581035}
Attestation can occur locally to setup secure communication channels between different enclaves on the same CPU. \cite[]{Anati2013}\label{ID_46728493}
It can also occur remotely. In this case, the attestation is not performed purely in hardware, but relies on additional so-called ``architectural enclaves''. \cite[]{sgx-explained}\label{ID_441975801}
These enclaves increase the size of the software TCB.\label{ID_1503953122}
They are also the main source for criticism of SGX as explained in \autoref{section:sgx-criticism}.\label{ID_419053144}

Code running in an enclave may not execute system calls. Any input/output must be handled by an untrusted wrapper. \cite[]{b}\label{ID_950941319}
It is still possible to securely communicate with enclaves using a key exchanged during the attestation process.\label{ID_798355081}
An enclave can use a key derived from its identity (initial measurement) to encrypt any data it wishes to expose to the untrusted world.\label{ID_971079488}

Multiple threads can be active at the same time in an enclave. \cite[]{McKeen2013}\label{ID_900329339}
The number of threads must be statically defined before the enclave is initialised. Also, the maximum enclave size must be fixed before initialising the enclave.\footnote{SGX version 2 allows a dynamic number of threads and dynamic memory size. No hardware is available at the time of writing.}\label{ID_1383514787}
SGX capable CPUs are available since the end of 2015.\footnote{\url{https://github.com/ayeks/SGX-hardware}}.\label{ID_1264019871}

\section{Enclave Development\label{ID_816398624}\label{section:sgx-usage}}
\lstinputlisting[label=listing:edl,caption=SGX SDK EDL,style=edl]{../kissdb-sgx/kissdb_t/kissdb.edl}\label{ID_326599406}

\section{Performance\label{ID_388809349}\label{section:sgx-perf}}
In principle, the CPU's full processing speed is available in SGX enclaves. This is an advantage over solutions with external secure elements.\label{ID_1639328080}
However, several factors have a observable performance impact on enclave performance.\label{ID_935750308}
Isolation is achieved by protecting an enclave's memory.\label{ID_88365959}
The additional memory layers introduced to enforce this isolation have an impact on access speed.\label{ID_921734519}
Using Intel's SDK on the other hand apparently results in a larger performance impact.\label{ID_589701637}
Existing findings from research are now presented.\label{ID_1990153751}

\autoref{figure:sgx-memory-access-speed} shows what performance overhead an enclave has on memory access.\label{ID_1704912531}
Pre-fetching hides most of the performance impact for sequential reads and writes. \cite[]{Arnautov2016}\label{ID_1962030152}
Random reads and writes highlight the actual performance impact.\label{ID_1830401881}
Two major factors impacting access times can be identified in the diagram. \cite[]{Arnautov2016}\label{ID_334642516}
\begin{description}\label{ID_1147500560}
\item[L3 cache size:] Enclave memory remains decrypted within the CPU's caches. As long as all enclave memory fits in the L3 cache, memory access times are roughly equal. If the cache is exceed, pages must be fetched from DRAM, decrypted and integrity-checked.\label{ID_635553127}
\item[Enclave Page Cache (EPC) size:] The EPC is a special section of DRAM. Pages that do not fit into EPC must be paged out to regular sections of DRAM. The EPC size is limited to 128MB on current SGX CPUs, of which 92MB can be used by user's enclaves. The rest is needed for metadata and Intel's architectural enclaves.\label{ID_766702921}
\end{description}\label{ID_1904020196}
\begin{figure}[htbp]
\begin{center}
	\includegraphics[width=0.8\textwidth]{content/images/sgx memory access speed}
\caption{\textbf{Memory access speed in Intel SGX enclaves.} Access times are normalised w.r.t native (non-enclave) access. The two limiting factors, L3 cache size and Enclave Page Cache (EPC) size are shown as grey lines. Sequential access hides some of the overhead due to pre-fetching. Reprinted from \cite[]{Arnautov2016}\label{ID_1423936467}\label{figure:sgx-memory-access-speed}\label{ID_1423936467}\label{figure:sgx-memory-access-speed}}

\end{center}
\end{figure}


This performance overhead means that enclave memory is a valuable resource and must be managed accordingly.\label{ID_813062369}
If possible, the combined size of all enclaves on a system should remain beneath the magical 92MB limit to avoid the 1000x performance penalty.\label{ID_1432243820}
Even better, the size of the L3 cache should not be exceeded.\label{ID_62762820}

The SDK provided by Intel should also be used with caution regarding performance. The SDK introduces the concept of E-calls and O-calls, which are synchronous transitions into and out of the enclave. \cite[]{b}\label{ID_1781049317}
\cite{Arnautov2016} evaluates how this can impact performance.\label{ID_905850038}
They compare different solutions for executing system calls from within an enclave.\label{ID_1493078645}
The first option is to use the untrusted wrapper as a synchronous proxy (E-call for every system call). The CPU must switch execution context, execute the system call, and pass the result back to the enclave. This adds a 10x overhead for \textit{pwrite} calls.\label{ID_642315590}
Better performance is achieved with a asynchronous executor thread pool outside of the enclave. This solution results in performance comparable to native execution. \cite[]{Arnautov2016}\label{ID_1629826277}
However, the Intel SDK can apparently not be used to build this complex kind of interaction.\label{ID_501911684}

\section{Known Criticism\label{ID_806492894}\label{section:sgx-criticism}}

\section{Applications\label{ID_54364136}}

\section{Conclusion\label{ID_95827774}}

\chapter{Related Work\label{ID_123293925}}

\section{Secure Databases\label{ID_1295642147}\label{section:secure-db}}

\section{Approaches to securing Legacy Code\label{ID_1261256917}}

\section{Hardening Applications with Intel SGX\label{ID_930530989}\label{section:sgx-hardening}}

\chapter{Case Studies\label{ID_1694829803}}
\todo{scenario, why databases}\label{ID_742761690}
\todo{step-wise approach: KissDB, SQLite}\label{ID_828430207}

\section{KissDB\label{ID_1828467557}}
\subsection{Security Objectives\label{ID_446058686}}
\subsection{Design Space\label{ID_579142082}}
\subsection{Intel SGX Helper Library\label{ID_335784211}}
\subsection{Hardening KissDB\label{ID_355880413}}
\subsection{Conclusion\label{ID_1103257591}}

\section{SQLite\label{ID_650094352}}
\subsection{Architecture\label{ID_1929909970}}
\subsection{Security Objectives\label{ID_1827488686}}
\subsection{Design Space\label{ID_1034380299}}
\subsection{Concepts\label{ID_556515413}}
\subsection{Conclusion\label{ID_1029119669}}

\chapter{Evaluation\label{ID_1795238683}}

\section{Performance\label{ID_1837416685}}

\section{Security Guarantees\label{ID_401277583}}

\section{Design Space\label{ID_416433960}}
criteria to help decide\label{ID_1289066951}

\chapter{Conclusion\label{ID_1572507625}}


